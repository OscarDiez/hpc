{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Module 4.  Distributed Training with TensorFlow - Multi-GPU and Multi-Node Simulation\n",
        "\n",
        "###Problem Statement:\n",
        "You are tasked with implementing and optimizing a neural network for image classification using TensorFlow's distributed strategies. First, you will use the MirroredStrategy for distributed training across multiple GPUs (Colab simulates multi-GPU setups). Then, you'll extend the setup to a multi-node distributed system using MultiWorkerMirroredStrategy to simulate multi-node training.\n",
        "\n",
        "You will implement and optimize the training process and compare the performance between the multi-GPU and multi-node setups.\n",
        "\n",
        "###Part 1: Multi-GPU Training using MirroredStrategy\n",
        "1. Define a Distributed Strategy: Use tf.distribute.MirroredStrategy() to simulate multi-GPU training.\n",
        "\n",
        "2. Dataset: Use the MNIST dataset, ensuring it is preprocessed and normalized.\n",
        "\n",
        "3. Model: Build a simple CNN using TensorFlow’s Sequential API.\n",
        "\n",
        "4. Training: Train the model using the distributed strategy and compare the performance with non-distributed training.\n",
        "\n",
        "5. Evaluation: Evaluate the model on the test set and ensure that the training converges correctly with multiple GPUs.\n",
        "\n",
        "\n",
        "\n",
        "###Part 2: Multi-Node Training using MultiWorkerMirroredStrategy\n",
        "1. Simulate a Multi-Node Setup: Set up MultiWorkerMirroredStrategy with appropriate environment variables (TF_CONFIG) for node communication.\n",
        "\n",
        "2. Training: Train the same model across simulated nodes and compare the performance.\n",
        "\n",
        "3. Evaluation: Evaluate the model after training in the multi-node setup."
      ],
      "metadata": {
        "id": "jVnd-UaBtRWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Starter Code for Multi-GPU Training (Part 1):"
      ],
      "metadata": {
        "id": "PUEicgrft1gp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqrUO5OlzpF",
        "outputId": "db529b90-2567-4516-dba0-8b2a3fc832c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.5160\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1480\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0943\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9801 - loss: 0.0671\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0529\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9715 - loss: 0.0886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0780678316950798, 0.9745000004768372]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the distributed strategy for multi-GPU training\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Use strategy.scope to define the distributed computations\n",
        "with strategy.scope():\n",
        "    # Define a simple neural network using CNN\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1 Instructions:\n",
        "1. Modify the model: Change the architecture from a simple feedforward network to a Convolutional Neural Network (CNN) to improve accuracy.\n",
        "2.  Experiment with batch size: Try different batch sizes (64, 128, 256) and observe the impact on performance.\n",
        "3. Measure training time: Compare the performance of running the training on a single GPU vs. using MirroredStrategy.\n",
        "\n",
        "###Example CNN Architecture:"
      ],
      "metadata": {
        "id": "PITbkvxVtVOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the model to a CNN architecture for better performance\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the CNN model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "ELYEG8JEtVlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2: Multi-Node Training with MultiWorkerMirroredStrategy (Colab Simulation)\n",
        "Define the TF_CONFIG Environment Variable: To simulate multi-node training, you need to set the TF_CONFIG environment variable that specifies the cluster configuration (which nodes are workers) and the role of each worker.\n",
        "\n",
        "###Training Code for Multi-Node Setup:"
      ],
      "metadata": {
        "id": "41GcXJhtt-Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the TF_CONFIG environment variable for multi-node training simulation\n",
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': {\n",
        "        'worker': [\"localhost:12345\", \"localhost:12346\"]  # Simulate two workers on different ports\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}  # Change 'index' to 1 on the second worker\n",
        "})\n",
        "\n",
        "# Define the strategy for distributed training across multiple nodes\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Use strategy.scope to ensure computations are distributed across nodes and GPUs\n",
        "with strategy.scope():\n",
        "    # Define a CNN architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the dataset\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "i025SoeVuB2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2 Instructions:\n",
        "1. Run the code on multiple workers: Simulate two workers on different ports by running the code on two different Colab instances or on a local machine with multi-node configuration.\n",
        "\n",
        "2. Set up the TF_CONFIG correctly: Ensure each worker is assigned the correct task (task: index in TF_CONFIG) and port.\n",
        "3. Experiment with different architectures: Try training larger models and observe how the multi-node setup scales the training.\n",
        "4. Checkpointing and saving: Implement a checkpointing system to save the model weights during training.\n",
        "\n",
        "###Deliverables:\n",
        "- Modified Multi-GPU Code (Part 1): Submit the modified CNN architecture and experiments using MirroredStrategy.\n",
        "- Multi-Node Simulation (Part 2): Submit the code for multi-node distributed training and provide results for different configurations.\n",
        "- Report: A short report (1-2 pages) summarizing:\n",
        " - Differences in training time between single GPU, multi-GPU, and multi-node setups.\n",
        " - Model accuracy and convergence speed in each setup.\n",
        " - Challenges faced in implementing the distributed training and how they were overcome.\n",
        "\n",
        "###Grading Rubric:\n",
        "- Correct Implementation of Multi-GPU Training (30 points): Proper use of MirroredStrategy and parallel training setup.\n",
        "\n",
        "- Multi-Node Setup and Execution (30 points): Correct use of MultiWorkerMirroredStrategy and simulation of multi-node behavior.\n",
        "- Performance Analysis (20 points): Evaluation of model performance in different setups.\n",
        "- Code Structure and Comments (10 points): Clean, well-documented code with appropriate comments.\n",
        "- Report and Findings (10 points): Summary of experiments and insights into distributed training.\n",
        "\n",
        "###Hints:\n",
        "- MirroredStrategy works well for multi-GPU setups. Use it to simulate parallelism with one GPU on Colab.\n",
        "TF_CONFIG is crucial for multi-node simulations. Understand how workers communicate in a distributed cluster.\n",
        "- Use TensorFlow's Checkpoint API to save model weights periodically during training.\n",
        "- Test with smaller models first, and then try scaling up with larger batch sizes and deeper networks."
      ],
      "metadata": {
        "id": "H4040E-juGHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "-----\n",
        "\n",
        "#The assignments finish here.  \n",
        "The third part below is not part of the assigment.\n",
        "\n",
        "-----\n",
        "-----\n"
      ],
      "metadata": {
        "id": "xcUwDyvC1bap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 3: Mixed Precision Training with Gradient Accumulation and cuDNN Optimizations (optional exercise to get 20% points)\n",
        "###Optimizing Distributed Training with Mixed Precision and Gradient Accumulation\n",
        "\n",
        "In this exercise, you will extend the previous work by incorporating mixed precision training and gradient accumulation to handle large models efficiently on GPUs. You will also explore how to optimize model training by leveraging cuDNN backend for convolution operations.\n",
        "\n",
        "The goal is to implement a high-performance training setup that optimally utilizes GPU resources, even in the case of large batch sizes that do not fit into GPU memory. By the end of this exercise, you will learn how to:\n",
        "\n",
        "Use mixed precision training to speed up training while reducing memory usage.\n",
        "Implement gradient accumulation to simulate training with larger batch sizes.\n",
        "Optimize CNN performance using cuDNN accelerations.\n",
        "\n",
        "###Instructions:\n",
        "\n",
        "1. Mixed Precision Training:\n",
        " - Use TensorFlow’s mixed precision API to convert the model’s computations to use mixed precision (FP16 and FP32) for faster training.\n",
        " - Ensure that the model’s optimizer is configured to handle mixed precision.\n",
        "\n",
        "2. Gradient Accumulation:\n",
        "\n",
        "  - Implement gradient accumulation to simulate large batch training, splitting a large batch into smaller sub-batches and accumulating gradients before performing an optimizer step.\n",
        "\n",
        "3. cuDNN Optimization:\n",
        " - Enable cuDNN optimizations to take full advantage of CUDA for convolutional operations, improving performance on supported GPUs.\n",
        "\n",
        "4. Multi-GPU Setup:\n",
        " - Use MirroredStrategy to distribute the model across multiple GPUs (if available) and synchronize the gradients across them.\n",
        "\n",
        "\n",
        "###Starter Code:"
      ],
      "metadata": {
        "id": "rH1FghaRx3nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Check if GPUs are available\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"GPUs Available: {len(gpus)}\")\n",
        "    for gpu in gpus:\n",
        "        # Enable cuDNN for maximum performance on NVIDIA GPUs\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"No GPUs available, training on CPU.\")\n",
        "\n",
        "# Enable mixed precision to improve performance and reduce memory usage\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Define the distributed strategy for multi-GPU training\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the dataset\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape the dataset for CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Use strategy.scope to ensure computations are distributed across GPUs\n",
        "with strategy.scope():\n",
        "    # Define a CNN model optimized for mixed precision training\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax', dtype='float32')  # Output layer must be float32\n",
        "    ])\n",
        "\n",
        "    # Use the mixed precision optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Define the gradient accumulation steps\n",
        "ACCUMULATION_STEPS = 4\n",
        "\n",
        "# Custom training loop with gradient accumulation\n",
        "@tf.function\n",
        "def train_step(batch_inputs, batch_labels, accumulated_gradients, step):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(batch_inputs, training=True)\n",
        "        loss = model.compiled_loss(batch_labels, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Accumulate gradients\n",
        "    for i in range(len(accumulated_gradients)):\n",
        "        accumulated_gradients[i] += gradients[i]\n",
        "\n",
        "    # Apply gradients after accumulation step\n",
        "    if (step + 1) % ACCUMULATION_STEPS == 0:\n",
        "        optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))\n",
        "        # Reset accumulated gradients\n",
        "        for i in range(len(accumulated_gradients)):\n",
        "            accumulated_gradients[i].assign(tf.zeros_like(accumulated_gradients[i]))\n",
        "\n",
        "# Train the model with gradient accumulation\n",
        "with strategy.scope():\n",
        "    accumulated_gradients = [tf.Variable(tf.zeros_like(var), trainable=False) for var in model.trainable_variables]\n",
        "    steps_per_epoch = len(x_train) // (64 * ACCUMULATION_STEPS)\n",
        "\n",
        "    for epoch in range(5):  # Train for 5 epochs\n",
        "        print(f\"Epoch {epoch+1}/{5}\")\n",
        "        step = 0\n",
        "\n",
        "        for batch_start in range(0, len(x_train), 64):\n",
        "            batch_inputs = x_train[batch_start: batch_start + 64]\n",
        "            batch_labels = y_train[batch_start: batch_start + 64]\n",
        "            train_step(batch_inputs, batch_labels, accumulated_gradients, step)\n",
        "            step += 1\n",
        "            if step >= steps_per_epoch:\n",
        "                break\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "4CQC3cNYzwhh",
        "outputId": "06bbefaa-a443-4b42-a8c6-f02afc7e125c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs Available: 1\n",
            "Error setting memory growth: Physical devices cannot be modified after being initialized\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:607: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"<ipython-input-6-4e2c0117c4d1>\", line 66, in train_step  *\n        gradients = tape.gradient(loss, model.trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 28, in handle\n        return self.value.handle\n\n    ValueError: DistributedVariable.handle is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e2c0117c4d1>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mbatch_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulated_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file71q72y83.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(batch_inputs, batch_labels, accumulated_gradients, step)\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-6-4e2c0117c4d1>\", line 66, in train_step  *\n        gradients = tape.gradient(loss, model.trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 28, in handle\n        return self.value.handle\n\n    ValueError: DistributedVariable.handle is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Elements:\n",
        "1. Mixed Precision Training:\n",
        "\n",
        " - We use TensorFlow’s mixed_precision API to convert part of the model to FP16, while ensuring that layers requiring higher precision (e.g., the final dense layer) remain in FP32.\n",
        " - The LossScaleOptimizer is used to avoid numerical instability during training with mixed precision.\n",
        "\n",
        "2. Gradient Accumulation:\n",
        "\n",
        " - Instead of performing an optimizer step after every batch, we accumulate gradients over several batches (ACCUMULATION_STEPS) and apply the gradients only once enough batches have been processed. This simulates training with larger batch sizes without exceeding GPU memory.\n",
        "\n",
        "3. cuDNN Optimizations:\n",
        "\n",
        "  - cuDNN optimizations are enabled for faster convolution operations on supported NVIDIA GPUs.\n",
        "  - This optimization allows for high-performance execution of convolutional layers, especially on NVIDIA GPUs.\n",
        "\n",
        "4. Multi-GPU Setup:\n",
        "- The MirroredStrategy is used to distribute training across multiple GPUs (if available), ensuring that the model is replicated on each device and gradients are synchronized across GPUs.\n",
        "\n",
        "## Deliverables:\n",
        "1. Complete Code: Submit the complete implementation of the optimized CNN model using mixed precision, gradient accumulation, and cuDNN optimizations.\n",
        "\n",
        "2. Report: A short report (1-2 pages) that describes:\n",
        "\n",
        "  - How mixed precision training and gradient accumulation were implemented.\n",
        "  - The performance gains observed in terms of training speed and memory usage.\n",
        "  - How cuDNN optimizations impacted the overall training performance.\n",
        "3. Test Results: Include the final test accuracy after 5 epochs of training.\n",
        "\n",
        "###Grading Rubric:\n",
        "- Correct Use of Mixed Precision (30 points): Proper implementation of TensorFlow’s mixed_precision API with correct handling of data types in layers.\n",
        "- Correct Implementation of Gradient Accumulation (30 points): Proper accumulation of gradients across mini-batches and application of the accumulated gradients at the correct intervals.\n",
        "- cuDNN Optimizations (20 points): The code should take advantage of cuDNN optimizations for convolutional layers.\n",
        "- Code Quality and Comments (10 points): Clear and well-documented code with appropriate comments explaining the steps.\n",
        "- Performance Testing and Analysis (10 points): Report should include observations on training speed and memory usage with mixed precision and gradient accumulation.\n",
        "\n",
        "###Hints:\n",
        "- Use mixed_precision.set_global_policy() to enable mixed precision training.\n",
        "- Make sure to reset accumulated gradients after applying them to the model.\n",
        "- Ensure that you are using cuDNN for optimizing convolution operations on supported GPUs by setting tf.config.experimental.set_memory_growth(gpu, True)."
      ],
      "metadata": {
        "id": "cD45JvPfz3OI"
      }
    }
  ]
}