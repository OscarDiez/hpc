{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d90c1b-74ab-4590-800f-2c162452350c",
   "metadata": {},
   "source": [
    "# Module 1. Practice 2. Simple Parallel Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3d58f-6bba-4b1f-bfae-7517af405b0b",
   "metadata": {},
   "source": [
    "## Introduction to simple Parallel Codes\n",
    "\n",
    "In High-Performance Computing (HPC), efficiently utilizing computational resources to solve problems faster is crucial. Python's `multiprocessing` module provides a robust and intuitive approach for parallel processing by allowing the creation and management of subprocesses. This is especially relevant in HPC where tasks are often CPU-bound and can benefit from the parallel execution across multiple cores of a processor.\n",
    "\n",
    "Parallel processing with the `multiprocessing` module effectively bypasses Python’s Global Interpreter Lock (GIL), which normally prevents multiple threads from executing Python bytecodes simultaneously. By using subprocesses instead of threads, each process gets its own Python interpreter and memory space, thus overcoming the limitations imposed by the GIL.\n",
    "\n",
    "In this practice, we will explore how to spawn multiple processes using the `multiprocessing` module. Each process will perform a simple computation—calculating the square of a number. This basic example serves as an introduction to the capabilities of parallel processing in Python, laying the groundwork for more complex parallel computations that are common in HPC applications, such as simulations, data analysis, and matrix operations. Understanding these fundamentals is essential for leveraging the full power of HPC resources to accelerate computation-intensive tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf131b-7d9b-4e11-8ecf-99327f9029f0",
   "metadata": {},
   "source": [
    "## Understanding Serial vs. Parallel Execution in Python\n",
    "\n",
    "In this section, we explore the differences between serial and parallel execution using Python's `multiprocessing` module. We will compare how the execution time varies when calculating squares of numbers both serially and in parallel.\n",
    "\n",
    "### Serial Execution\n",
    "In serial execution, tasks are completed one after the other. This method does not utilize additional CPU cores, which can result in slower performance for CPU-bound tasks.\n",
    "\n",
    "### Parallel Execution\n",
    "Parallel execution allows multiple processes to run simultaneously, leveraging multiple CPU cores. This can significantly reduce the time required to complete CPU-intensive tasks by distributing the workload across available resources.\n",
    "\n",
    "## Estimating the Value of π Using Monte Carlo Simulation\n",
    "\n",
    "### What is Monte Carlo Simulation?\n",
    "Monte Carlo simulation is a statistical technique that allows us to compute an approximation of a value through random sampling. This method is often used in fields such as physics, finance, and engineering to solve problems that might be deterministic in principle but complex in practice.\n",
    "\n",
    "### Monte Carlo Simulation to Estimate π\n",
    "In this exercise, we use a Monte Carlo method to estimate the value of π. The principle behind this is simple: by randomly generating points within a square that encloses a quarter circle, we can estimate π based on the ratio of points that fall inside the circle to the total number of points. \n",
    "\n",
    "![Pi Monte carlo simulation](https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif)\n",
    "\n",
    "### Serial vs. Parallel Execution\n",
    "\n",
    "#### Serial Execution\n",
    "In serial execution, points are generated one at a time, and each point's position relative to the quarter circle is calculated sequentially. This approach does not leverage additional computational resources that might be available, such as multiple CPU cores, making it slower for a large number of points.\n",
    "\n",
    "#### Parallel Execution\n",
    "Parallel execution divides the task among multiple processes, allowing the simultaneous generation and evaluation of points. This method can significantly speed up the computation by utilizing multiple cores, thus demonstrating the power of parallel processing in computational tasks that are both independent and identically distributed.\n",
    "\n",
    "### Implementation\n",
    "We implement both serial and parallel approaches to estimate π. The parallel computation uses Python's `multiprocessing` module, which allows us to create multiple processes that can run on different cores and handle separate chunks of the task independently. The results from each process are then combined to get \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58a9410-5d1b-4d5c-bbc8-a158ccb5a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serial calculation of π:\n",
      "Serial estimate of π: 3.1415188\n",
      "Serial execution time: 8.118415594100952 seconds\n",
      "\n",
      "Starting parallel calculation of π:\n",
      "Parallel estimate of π: 3.1419046\n",
      "Parallel execution time: 4.126979827880859 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def monte_carlo_pi_part(n, queue):\n",
    "    count = 0\n",
    "    for _ in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x**2 + y**2 <= 1:\n",
    "            count += 1\n",
    "    queue.put(count)\n",
    "\n",
    "def serial_monte_carlo_pi(n):\n",
    "    count = 0\n",
    "    for _ in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x**2 + y**2 <= 1:\n",
    "            count += 1\n",
    "    return 4 * count / n\n",
    "\n",
    "def parallel_monte_carlo_pi(total_samples, num_processes):\n",
    "    queue = Queue()\n",
    "    processes = []\n",
    "    samples_per_process = total_samples // num_processes\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_processes):\n",
    "        p = Process(target=monte_carlo_pi_part, args=(samples_per_process, queue))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    total_count = 0\n",
    "    for _ in range(num_processes):\n",
    "        total_count += queue.get()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    end_time = time.time()\n",
    "\n",
    "    pi_estimate = 4 * total_count / total_samples\n",
    "    print(f\"Parallel estimate of π: {pi_estimate}\")\n",
    "    print(f\"Parallel execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_samples = 20_000_000\n",
    "    num_processes = 4\n",
    "\n",
    "    print(\"Starting serial calculation of π:\")\n",
    "    start_time = time.time()\n",
    "    pi_estimate = serial_monte_carlo_pi(n_samples)\n",
    "    end_time = time.time()\n",
    "    print(f\"Serial estimate of π: {pi_estimate}\")\n",
    "    print(f\"Serial execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "    print(\"\\nStarting parallel calculation of π:\")\n",
    "    parallel_monte_carlo_pi(n_samples, num_processes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8b410-4975-4529-afa5-d95819540719",
   "metadata": {},
   "source": [
    "## Parallelizing a Simple Loop with `multiprocessing.Pool`\n",
    "\n",
    "### Understanding `multiprocessing.Pool`\n",
    "The `multiprocessing.Pool` class is a powerful tool in Python's multiprocessing module that simplifies the process of distributing your work among multiple worker processes. This allows for parallel processing on multi-core machines which can lead to significant reductions in execution time, especially for CPU-bound tasks.\n",
    "\n",
    "### How Does a Pool Work?\n",
    "A `Pool` manages a number of worker processes and distributes tasks to them. When using a `Pool`, you don’t need to manage the worker processes yourself. Instead, you just specify the number of workers, and the pool automatically handles the task distribution, execution, and collection of results.\n",
    "\n",
    "### Use Case: Parallelizing Loops\n",
    "Often in programming, you encounter loops where each iteration is independent of the others. These are perfect candidates for parallel processing. By distributing iterations across multiple processes, you can complete the entire loop significantly faster than executing it serially.\n",
    "\n",
    "### Example: Computing Squares\n",
    "Consider a simple task where you need to compute the square of each number in a list. Serially, this would involve processing each number one after the other. In parallel, however, we can distribute these numbers across multiple processes, each calculating the square independently, thus completing the task more quickly.\n",
    "\n",
    "### Advantages of Using a Pool\n",
    "- **Efficiency**: Utilizes all available CPU cores, reducing overall processing time.\n",
    "- **Simplicity**: The API is straightforward, abstracting much of the complexity involved in process management.\n",
    "- **Flexibility**: Offers various ways to distribute tasks (e.g., `map`, `apply`, `starmap`).\n",
    "\n",
    "### Practical Example\n",
    "We will demonstrate this with a Python script that uses a `Pool` to compute the squares of numbers in a list in parallel. This example will help illustrate the reduction in execution time and the effective use of system resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945a262a-8dd3-45fe-9b3c-ab61960aed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def compute_square(num):\n",
    "    return num * num\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = list(range(10))  # List of numbers from 0 to 9\n",
    "    \n",
    "    # Creating a pool of 4 worker processes\n",
    "    with Pool(4) as pool:\n",
    "        # Mapping 'compute_square' function to the numbers list\n",
    "        squares = pool.map(compute_square, numbers)\n",
    "    \n",
    "    # Printing the results\n",
    "    print(\"Squares:\", squares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f42efd-70b3-4828-a79b-5aaaca0da617",
   "metadata": {},
   "source": [
    "## Parallel Execution with `concurrent.futures`\n",
    "\n",
    "### Introduction to `concurrent.futures`\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables. Introduced in Python 3.2, it abstracts away many of the complexities involved in directly managing threads or processes. The module includes `ThreadPoolExecutor` and `ProcessPoolExecutor` which encapsulate thread-based and process-based parallel execution, respectively.\n",
    "\n",
    "### Why Use `concurrent.futures`?\n",
    "The `concurrent.futures` module simplifies parallel execution by managing a pool of threads or processes, handling task submission, and returning futures. Futures represent the result of a computation that may not be complete yet, allowing the execution to continue without blocking.\n",
    "\n",
    "### Advantages of `ProcessPoolExecutor`\n",
    "- **Ease of Use**: The API simplifies running tasks in parallel and is easy to integrate into existing code.\n",
    "- **Flexibility**: Allows specifying the number of worker processes, letting the system allocate resources efficiently.\n",
    "- **Asynchronous Execution**: Returns future objects, enabling asynchronous programming patterns and non-blocking calls.\n",
    "\n",
    "### Use Case: Calculating Squares in Parallel\n",
    "A common use case for parallel processing is the independent computation of results from a list of inputs. Here, we will demonstrate using `ProcessPoolExecutor` to calculate the squares of numbers in a list. This example illustrates the ease of setup and potential speed improvements when using this method for CPU-intensive tasks.\n",
    "\n",
    "### Practical Example\n",
    "Next, we will provide a Python script using `ProcessPoolExecutor` to demonstrate how straightforward and powerful this tool can be for parallelizing a simple loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c17f927-3284-4c27-9989-fc99b36808eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def compute_square(num):\n",
    "    return num * num\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = list(range(10))  # List of numbers from 0 to 9\n",
    "    \n",
    "    # Creating a ProcessPoolExecutor with 4 worker processes\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        # Using executor.map to apply 'compute_square' function across the numbers list in parallel\n",
    "        squares = list(executor.map(compute_square, numbers))\n",
    "    \n",
    "    # Printing the results\n",
    "    print(\"Squares:\", squares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b389404-717c-4c0b-b538-90078f8b4adf",
   "metadata": {},
   "source": [
    "## Case Study: Parallel Matrix Multiplication\n",
    "\n",
    "### Significance of Matrix Operations in Scientific Computing\n",
    "Matrix operations are fundamental to many scientific computations, including physics simulations, statistical analysis, and engineering calculations. These operations, especially matrix multiplication, are computationally intensive and often constitute the bottleneck in performance for algorithms in fields such as machine learning and numerical simulation.\n",
    "\n",
    "### Suitability for Parallel Processing\n",
    "Matrix multiplication can be effectively decomposed into smaller, independent computations, making it an ideal candidate for parallel processing. Since each element of the product matrix can be calculated independently of the others, parallel algorithms can distribute these calculations across multiple processors. This distribution significantly speeds up the computation as it leverages the computational power of multiple cores simultaneously.\n",
    "\n",
    "### Benefits of Parallel Matrix Multiplication\n",
    "- **Speed**: Parallel processing can drastically reduce computation time, which is crucial for handling large datasets or real-time processing.\n",
    "- **Efficiency**: Utilizing multiple cores or processors allows for more efficient use of hardware resources.\n",
    "- **Scalability**: As matrix size grows, parallel processing becomes increasingly advantageous, offering better scalability compared to serial computations.\n",
    "\n",
    "### Practical Implementation\n",
    "In the following section, we will explore both serial and parallel implementations of matrix multiplication using Python's `numpy` library for handling matrices and the `multiprocessing` module to facilitate parallel computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430fad7b-9037-4270-b7e4-cadc5a6f1f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultant Matrix C (Serial): [[24.90881819 19.54776263 21.77500841 ... 25.56550667 27.08250322\n",
      "  25.73052442]\n",
      " [25.16163819 21.44735579 22.42583682 ... 25.43692325 25.00855225\n",
      "  26.67256762]\n",
      " [25.86303127 21.11208763 22.35929871 ... 25.33424566 27.3752456\n",
      "  24.11021893]\n",
      " ...\n",
      " [26.74466745 21.89882931 23.79751566 ... 26.20412994 26.99904508\n",
      "  26.28365008]\n",
      " [25.41116273 20.5938019  20.57125531 ... 24.97577627 27.47758086\n",
      "  25.43915447]\n",
      " [23.84914601 20.8168041  23.14614466 ... 28.2597226  27.52611629\n",
      "  25.61926105]]\n",
      "Resultant Matrix C (Parallel): [[24.90881819 19.54776263 21.77500841 ... 25.56550667 27.08250322\n",
      "  25.73052442]\n",
      " [25.16163819 21.44735579 22.42583682 ... 25.43692325 25.00855225\n",
      "  26.67256762]\n",
      " [25.86303127 21.11208763 22.35929871 ... 25.33424566 27.3752456\n",
      "  24.11021893]\n",
      " ...\n",
      " [26.74466745 21.89882931 23.79751566 ... 26.20412994 26.99904508\n",
      "  26.28365008]\n",
      " [25.41116273 20.5938019  20.57125531 ... 24.97577627 27.47758086\n",
      "  25.43915447]\n",
      " [23.84914601 20.8168041  23.14614466 ... 28.2597226  27.52611629\n",
      "  25.61926105]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Function for serial matrix multiplication using NumPy's dot product\n",
    "def matrix_multiply(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "# Function to multiply a matrix chunk by another matrix\n",
    "def multiply_chunk(args):\n",
    "    A_chunk, B = args\n",
    "    return np.dot(A_chunk, B)\n",
    "\n",
    "# Function for parallel matrix multiplication\n",
    "def parallel_matrix_multiply(A, B, n_processes):\n",
    "    chunk_size = len(A) // n_processes  # Determine the size of each chunk\n",
    "    chunks = [(A[i:i + chunk_size], B) for i in range(0, len(A), chunk_size)]\n",
    "    \n",
    "    # Create a pool of worker processes\n",
    "    with Pool(n_processes) as pool:\n",
    "        result_chunks = pool.map(multiply_chunk, chunks)\n",
    "    \n",
    "    # Combine the chunks back into a full result matrix\n",
    "    return np.vstack(result_chunks)\n",
    "\n",
    "# Creating two random matrices of size 100x100\n",
    "A = np.random.rand(100, 100)\n",
    "B = np.random.rand(100, 100)\n",
    "\n",
    "# Performing serial and parallel matrix multiplication\n",
    "C_serial = matrix_multiply(A, B)\n",
    "C_parallel = parallel_matrix_multiply(A, B, 4)\n",
    "\n",
    "# Output results\n",
    "print(\"Resultant Matrix C (Serial):\", C_serial)\n",
    "print(\"Resultant Matrix C (Parallel):\", C_parallel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0149a8-dfad-4f6b-abf1-a824abea625d",
   "metadata": {},
   "source": [
    "## Advanced Topics in Parallel Programming\n",
    "\n",
    "### Scalability Considerations\n",
    "Scalability in parallel programming refers to the ability of a process or system to handle a growing amount of work or its potential to be enlarged to accommodate that growth. When developing parallel applications, it's crucial to design systems that can scale efficiently as the number of processors or tasks increases. Key considerations include:\n",
    "- **Load Balancing**: Distributing work evenly across all processors to avoid scenarios where some nodes are idle while others are overloaded.\n",
    "- **Overhead Management**: Keeping the communication and synchronization overhead to a minimum as the system scales up.\n",
    "\n",
    "### Understanding Deadlocks and Race Conditions\n",
    "- **Deadlocks**: A deadlock occurs when two or more processes are each waiting for the other to release a resource they need to continue execution. This situation results in a standstill where none of the processes can proceed.\n",
    "- **Race Conditions**: A race condition happens when multiple processes or threads manipulate shared data concurrently. The final value of the shared data depends on which process/thread completes last, leading to unpredictable results if not properly managed.\n",
    "\n",
    "### Synchronization Issues\n",
    "Synchronization is critical in parallel programming to ensure that multiple processes or threads can operate safely when sharing resources or data. Proper synchronization can prevent race conditions and ensure data integrity. Common synchronization mechanisms include:\n",
    "- **Locks**: Allow only one thread to access a resource at a time.\n",
    "- **Semaphores**: A more flexible mechanism that uses counters to control access to one or more shared resources.\n",
    "\n",
    "### Practical Example: Using Locks to Handle Race Conditions\n",
    "To demonstrate the importance of synchronization, we'll use a Python example where multiple processes increment a shared counter. Without proper synchronization, the final count could be incorrect due to race conditions. We'll use a `Lock` to ensure that only one process can increment the counter at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0965b8-a5ca-4984-a75c-03cb72d2fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Value: 400\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Lock, Value\n",
    "\n",
    "# Function that increments a shared counter\n",
    "def increment(shared_value, lock):\n",
    "    with lock:\n",
    "        # Critical section: only one process can execute this block at a time\n",
    "        for _ in range(100):\n",
    "            shared_value.value += 1\n",
    "\n",
    "# Main block to set up and run processes\n",
    "if __name__ == \"__main__\":\n",
    "    # Shared value that all processes will increment\n",
    "    shared_value = Value('i', 0)\n",
    "    \n",
    "    # Lock to synchronize access to the shared value\n",
    "    lock = Lock()\n",
    "    \n",
    "    # List of processes that will increment the shared value\n",
    "    processes = [Process(target=increment, args=(shared_value, lock)) for _ in range(4)]\n",
    "    \n",
    "    # Start all processes\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # Output the final value of the shared counter\n",
    "    print(\"Final Value:\", shared_value.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a0cca-1115-4329-a6cc-9f00ca413ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "End of the practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
